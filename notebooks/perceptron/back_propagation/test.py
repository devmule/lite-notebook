# seed для псевдослучайных чисел,
# чтобы при каждом запуске получался один и тот же результат
np.random.seed(2)


# генерируем случайные синапсы
synapses = [
    np.random.random((2, 8)) * 2 - 1,  # 2 нейрона  -> 8 нейронов
    np.random.random((8, 1)) * 2 - 1   # 8 нейронов -> 1 нейрон
]


# создаём обучающую выборку, в неё входят входные и
# соответствующие им выходные значения для функции XOR
inp = [[0, 0], [0, 1], [1, 0], [1, 1]]
out = [[0],    [1],    [1],    [0]   ]


# проводим обучение
learn(inp, out, synapses,
    epochs=10000,  # количество проходов по выборке
    lr=.5,  # коэффициент обучения
    err_print_frequency=100,  # период вывода Loss
    err_end_coef=0.001,  # ошибка при достижении которой обучение завершается дострочно
)


# тестируем обученную нейросеть,
# для этого сравниваем полученное и ожидаемое значения
for i in range(len(inp)):
    print("получено: ", round(feedforward(inp[i], synapses)[0], 3), ", ожидалось: ", out[i])
