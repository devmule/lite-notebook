>>> md

# Прямое распространение сигнала

___

Персептроны в любом случае работают над какими-то данными, а не сами по себе.

Эти данные персептрон получает во входной слой в виде числовых значений а затем "передаёт" их последующим слоям.

### Как происходит эта передача?

Мы мельком рассматривали процесс под названием **feedforward** раньше. Давайте повторим его на примере.

Допустим, у нас есть персептрон без скрытых слоёв. Всего два слоя - входной и выходной.

![0layers](ff1.png?style=center "без скрытых слоёв")

Синапсы у персептрона есть, их веса указаны. Есть входные значения. Что делать дальше?
А дальше по формуле ниже расчитывается значение нашего единственного выходного нейрона.
$$ y = f(\sum_{i=1}^{n} w_i x_i) $$
### Что же в этой формуле происходит?
1. Перемножаются значения соседних нейронов ***x*** со значениями соответствующего синапса ***w***.
2. Все полученные произведения складываются. Полученная сумма является **неактивированным** значением нейрона.
3. Неактивированное значение нейрона **активируется** с помощью функции активации, у нас это **сигмоида**.
$$ сигмоида - σ(x)= \frac{1}{1 + e^{-x}} $$
Итак, расчитываем значение нейрона.
$$ O_1 = σ(0.5 * 0 + 1 * 2) = σ(2) ≈ 0.88 $$

### Хорошо, нашли. Но что если нейронов много? Все перебирать?

Нет, перебирать их не нужно. Есть одна хитрость с сумматорами!

Можно представить синапсы как матрицу размером **m** на **n**. При том, размеры **m** и **n** будут равны количествам
нейронов в слоях, которые эти синапсы соединяют. А сами слои представить как векторы (та же матрица, только одна из сторон равна единице).

Чтобы понимать математику ниже стоит знать как работает [перемножение матриц](http://matrixmultiplication.xyz/).

И если перемножить матрицу синапсов с вектором входного слоя, то получится вектор с **неактивированными** значениями выходного слоя.

$$ Y_{неактив.} = W·X $$

Для примера выше, перемножение в матричном виде произойдёт вот так:
![0layers](ff1.gif?style=center "перемножение матрицы")
Але-оп. И мы получили `2` - неактивированное значение единственного нейрона выходного слоя.

### А давайте рассмотрим другой пример!
И добавим несколько нейронов в выходной слой:
![0layers](ff2.png?style=center "много нейронов")
Теперь размер входного слоя равен `2`, а выходного `3`. Размер матрицы синапсов `3×2`.
![0layers](ff2.gif?style=center "перемножение матрицы 3×2")
Остаётся только **"активировать"** значения нейронов.


А давайте теперь реализуем процесс прямого распространения на языке программирования **Python 3**.

___

## Реализация

>>> fetch
text: ff1_txt = ff1.py
text: ff2_txt = ff2.py

>>> code id=editor_1 run
>>> js
    var editor_1 = ace.edit("editor_1");
    editor_1.getSession().setValue(ff1_txt)

    let code_output_1 = lite_notebook.elements.code_output();
    lite_notebook.screen.appendChild(code_output_1);

    code_output_1.attachEditor(editor_1);


>>> md

### А если слоёв несколько?

Если слоёва несколько, то для каждого нового слоя используются активиованные значения предыдущего слоя!

>>> code id=editor_2 run
>>> js
    var editor_2 = ace.edit("editor_2");
    editor_2.getSession().setValue(ff2_txt)

    let code_output_2 = lite_notebook.elements.code_output();
    lite_notebook.screen.appendChild(code_output_2);

    code_output_2.attachEditor(editor_2);